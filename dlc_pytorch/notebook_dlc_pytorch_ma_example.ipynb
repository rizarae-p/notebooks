{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d92080",
   "metadata": {},
   "source": [
    "# Creating a DeepLabCut Multi-Animal PyTorch Project\n",
    "\n",
    "- Copy a project to a new folder\n",
    "- Increase the iteration in the config file\n",
    "- set `default_net_type: dekr_w32` in config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37142aee",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11623415",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e1fe21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deeplabcut'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdeeplabcut\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeplabcut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpose_estimation_pytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     analyze_videos,\n\u001b[1;32m      9\u001b[0m     convert_detections2tracklets,\n\u001b[1;32m     10\u001b[0m     train_network,\n\u001b[1;32m     11\u001b[0m     inference_network,\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deeplabcut'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import yaml\n",
    "from pathlib\\\n",
    "import Path\n",
    "\n",
    "import albumentations as A\n",
    "import deeplabcut\n",
    "from deeplabcut.pose_estimation_pytorch import (\n",
    "    analyze_videos,\n",
    "    convert_detections2tracklets,\n",
    "    train_network,\n",
    "    inference_network,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8be3c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rae/.pyenv/shims/python\r\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a620661f",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/niels/Documents/upamathis/datasets\"\n",
    "project = f\"{root}/dev-pytorch-ma-pen-2023-06-14\"\n",
    "config_path = f\"{project}/config.yaml\"\n",
    "\n",
    "model_prefix = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471bfa3c",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml(path):\n",
    "    try :\n",
    "        with open(path, \"r\") as stream:\n",
    "            try:\n",
    "                return yaml.safe_load(stream)\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)\n",
    "    except :\n",
    "        raise FileNotFoundError(\"An eero occured whilereading the file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ff3fa",
   "metadata": {},
   "source": [
    "## Create the PyTorch Training Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffles = deeplabcut.create_training_dataset(\n",
    "    config_path,\n",
    "    num_shuffles=2,\n",
    "    net_type=\"dekr_w18\",\n",
    ")\n",
    "\n",
    "shuffles = None\n",
    "if shuffles is not None:\n",
    "    for shuffle in shuffles:\n",
    "        print(80 * \"-\")\n",
    "        print(f\"split = {shuffle[0]}\")\n",
    "        print(f\"train_indices = {list(shuffle[2][0])}\")\n",
    "        print(f\"test_indices = {list(shuffle[2][1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b46c40",
   "metadata": {},
   "source": [
    "Go to ```config.yaml``` and set \n",
    "\n",
    "- `batch_size: 1`\n",
    "- `default_track_method: box`\n",
    "\n",
    "\n",
    "Go to ```dlc-models/iteration-2/devMay17-trainset95shuffle1/train/pytorch_config.yaml``` and set \n",
    "\n",
    "- `batch_size: 1`\n",
    "- `device: cpu`\n",
    "- `epochs: 100`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb6b8ab",
   "metadata": {},
   "source": [
    "## Cool Machine Learning Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8c072",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(config_path: dict):\n",
    "    print(80 * \"-\")\n",
    "    print(\"Creating image augmentation transforms\")\n",
    "    cfg = read_yaml(config_path)\n",
    "    transform = A.Compose(\n",
    "        [\n",
    "            A.Affine(\n",
    "                scale=(0.75, 1.5),\n",
    "                rotate=(-30, 30),\n",
    "                translate_px=(-40, 40),\n",
    "            ),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.MotionBlur(),\n",
    "            A.PixelDropout(),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ],\n",
    "        keypoint_params=A.KeypointParams(\n",
    "            format='xy',\n",
    "            remove_invisible=False,\n",
    "            label_fields=['class_labels']\n",
    "        )\n",
    "    )\n",
    "    print(80 * \"-\")\n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb41a3",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85388c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(config_path, shuffle=1, transform=None, model_prefix=\"\"):\n",
    "    \"\"\"Trains the model and evaluates it on a given dataset\"\"\"\n",
    "    # Training the network\n",
    "    print(\"Training started\")\n",
    "    start_time = time.time()\n",
    "    train_network(\n",
    "        config_path,\n",
    "        shuffle=shuffle,\n",
    "        transform=transform,\n",
    "        model_prefix=model_prefix,\n",
    "    )\n",
    "    delta_time = time.time() - start_time\n",
    "    print(f\"Training ended after {delta_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# No flip transform here; it's confusing the model, better to keep left right for the pen ends\n",
    "transform = get_transform(config_path)\n",
    "train(config_path, shuffle=1, transform=transform, model_prefix=model_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55643247",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9831c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = A.Compose(\n",
    "    [A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])],\n",
    "    keypoint_params=A.KeypointParams(\n",
    "        format='xy',\n",
    "        remove_invisible=False,\n",
    "        # label_fields=['class_labels']\n",
    "    )\n",
    ")\n",
    "\n",
    "inference_network(\n",
    "    config_path,\n",
    "    shuffle=1,\n",
    "    model_prefix=model_prefix,\n",
    "    load_epoch=-1,\n",
    "    transform=test_transform,\n",
    "    plot=False,\n",
    "    evaluate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca3335",
   "metadata": {},
   "source": [
    "### Video Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"{project}/videos/multipen.mov\"\n",
    "output_folder = f\"{project}/videos-analysis-output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1353b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_transform = A.Compose(\n",
    "    [A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])],\n",
    ")\n",
    "\n",
    "results = analyze_videos(\n",
    "    config_path,\n",
    "    data_path=data_path,\n",
    "    output_folder=output_folder,\n",
    "    dataset_index=0,\n",
    "    shuffle=1,\n",
    "    snapshot_index=-1,\n",
    "    model_prefix=model_prefix,\n",
    "    batch_size=1,\n",
    "    device=\"cpu\",\n",
    "    transform=analysis_transform,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72cc60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Results for {Path(results[0][0]).name}\")\n",
    "results[0][1].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_detections2tracklets(\n",
    "    config_path,\n",
    "    str(data_path),\n",
    "    dataset_index=0,\n",
    "    shuffle=1,\n",
    "    output_folder=output_folder,\n",
    "    modelprefix=\"\",\n",
    "    track_method=\"box\",\n",
    ")\n",
    "deeplabcut.stitch_tracklets(\n",
    "    str(config_path),\n",
    "    [str(data_path)],\n",
    "    shuffle=1,\n",
    "    trainingsetindex=0,\n",
    "    destfolder=str(output_folder),\n",
    "    n_tracks=2,\n",
    "    modelprefix=\"\",\n",
    "    save_as_csv=True,\n",
    "    track_method=\"box\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(\n",
    "    config_path,\n",
    "    [data_path],\n",
    "    videotype=\".mov\",\n",
    "    shuffle=1,\n",
    "    trainingsetindex=0,\n",
    "    destfolder=output_folder,\n",
    "    modelprefix=\"\",\n",
    "    track_method=\"box\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3eb3d",
   "metadata": {},
   "source": [
    "## Config Files\n",
    "\n",
    "### `config.yaml`\n",
    "\n",
    "```yaml\n",
    "    # Project definitions (do not edit)\n",
    "Task: dev-ma\n",
    "scorer: pen\n",
    "date: Jun14\n",
    "multianimalproject: true\n",
    "identity: false\n",
    "\n",
    "# Project path (change when moving around)\n",
    "project_path: .../datasets/dev-pytorch-ma-pen-2023-06-14\n",
    "\n",
    "# Annotation data set configuration (and individual video cropping parameters)\n",
    "video_sets:\n",
    "  .../dev-ma-pen-2023-06-14/videos/multipen.mov:\n",
    "    crop: 0, 480, 0, 640\n",
    "individuals:\n",
    "- individual1\n",
    "- individual2\n",
    "uniquebodyparts: []\n",
    "multianimalbodyparts:\n",
    "- capTip\n",
    "- bottom\n",
    "bodyparts: MULTI!\n",
    "\n",
    "# Fraction of video to start/stop when extracting frames for labeling/refinement\n",
    "start: 0\n",
    "stop: 1\n",
    "numframes2pick: 25\n",
    "\n",
    "# Plotting configuration\n",
    "skeleton: []\n",
    "skeleton_color: black\n",
    "pcutoff: 0.6\n",
    "dotsize: 12\n",
    "alphavalue: 0.7\n",
    "colormap: rainbow\n",
    "\n",
    "# Training,Evaluation and Analysis configuration\n",
    "TrainingFraction:\n",
    "- 0.8\n",
    "iteration: 0\n",
    "default_net_type: dekr_w18\n",
    "default_augmenter: multi-animal-imgaug\n",
    "default_track_method: box\n",
    "snapshotindex: -1\n",
    "batch_size: 1\n",
    "\n",
    "# Cropping Parameters (for analysis and outlier frame detection)\n",
    "cropping: false\n",
    "# if cropping is true for analysis, then set the values here:\n",
    "x1: 0\n",
    "x2: 640\n",
    "y1: 277\n",
    "y2: 624\n",
    "\n",
    "# Refinement configuration (parameters from annotation dataset configuration also relevant in this stage)\n",
    "corner2move2:\n",
    "- 50\n",
    "- 50\n",
    "move2corner: true\n",
    "```\n",
    "\n",
    "### `train/pytorch_config.yaml`\n",
    "\n",
    "```yaml\n",
    "batch_size: 1\n",
    "cfg_path: \n",
    "  .../datasets/dev-pytorch-ma-pen-2023-06-14/config.yaml\n",
    "criterion:\n",
    "  locref_huber_loss: true\n",
    "  loss_weight_locref: 0.02\n",
    "  type: PoseLoss\n",
    "data:\n",
    "  covering: true\n",
    "  gaussian_noise: 12.75\n",
    "  hist_eq: true\n",
    "  motion_blur: true\n",
    "  normalize_images: true\n",
    "  rotation: 30\n",
    "  scale_jitter:\n",
    "  - 0.5\n",
    "  - 1.25\n",
    "  translation: 40\n",
    "device: cpu\n",
    "display_iters: 1000\n",
    "epochs: 100\n",
    "model:\n",
    "  backbone:\n",
    "    type: HRNet\n",
    "    model_name: hrnet_w18\n",
    "  heatmap_head:\n",
    "    type: HeatmapDEKRHead\n",
    "    channels:\n",
    "    - 270\n",
    "    - 64\n",
    "    - 3\n",
    "    num_blocks: 1\n",
    "    dilation_rate: 1\n",
    "    final_conv_kernel: 1\n",
    "  locref_head:\n",
    "    type: OffsetDEKRHead\n",
    "    channels:\n",
    "    - 270\n",
    "    - 30\n",
    "    - 2\n",
    "    num_offset_per_kpt: 15\n",
    "    num_blocks: 1\n",
    "    dilation_rate: 1\n",
    "    final_conv_kernel: 1\n",
    "  pose_model:\n",
    "    stride: 8\n",
    "  target_generator:\n",
    "    type: DEKRGenerator\n",
    "    num_joints: 2\n",
    "    pos_dist_thresh: 17\n",
    "optimizer:\n",
    "  params:\n",
    "    lr: 0.01\n",
    "  type: SGD\n",
    "pos_dist_thresh: 17\n",
    "predictor:\n",
    "  type: DEKRPredictor\n",
    "  num_animals: 2\n",
    "save_epochs: 50\n",
    "scheduler:\n",
    "  params:\n",
    "    lr_list:\n",
    "    - - 0.05\n",
    "    - - 0.005\n",
    "    milestones:\n",
    "    - 10\n",
    "    - 430\n",
    "  type: LRListScheduler\n",
    "seed: 42\n",
    "solver:\n",
    "  type: BottomUpSingleAnimalSolver\n",
    "with_center: true\n",
    "project_path: .../datasets/dev-pytorch-ma-pen-2023-06-14\n",
    "pose_cfg_path: \n",
    "  .../datasets/dev-pytorch-ma-pen-2023-06-14/dlc-models/iteration-0/dev-maJun14-trainset80shuffle1/train/pose_cfg.yaml\n",
    "```\n",
    "\n",
    "### `train/pose_cfg.yaml`\n",
    "\n",
    "```yaml\n",
    "all_joints:\n",
    "- - 0\n",
    "- - 1\n",
    "all_joints_names:\n",
    "- capTip\n",
    "- bottom\n",
    "alpha_r: 0.02\n",
    "apply_prob: 0.5\n",
    "batch_size: 8\n",
    "contrast:\n",
    "  clahe: true\n",
    "  claheratio: 0.1\n",
    "  histeq: true\n",
    "  histeqratio: 0.1\n",
    "convolution:\n",
    "  edge: false\n",
    "  emboss:\n",
    "    alpha:\n",
    "    - 0.0\n",
    "    - 1.0\n",
    "    strength:\n",
    "    - 0.5\n",
    "    - 1.5\n",
    "  embossratio: 0.1\n",
    "  sharpen: false\n",
    "  sharpenratio: 0.3\n",
    "crop_sampling: hybrid\n",
    "crop_size:\n",
    "- 400\n",
    "- 400\n",
    "cropratio: 0.4\n",
    "dataset: training-datasets/iteration-0/UnaugmentedDataSet_dev-maJun14/dev-ma_pen80shuffle1.pickle\n",
    "dataset_type: multi-animal-imgaug\n",
    "decay_steps: 30000\n",
    "display_iters: 500\n",
    "global_scale: 0.8\n",
    "init_weights: .../DLCdev/deeplabcut\n",
    "intermediate_supervision: false\n",
    "intermediate_supervision_layer: 12\n",
    "location_refinement: true\n",
    "locref_huber_loss: true\n",
    "locref_loss_weight: 0.05\n",
    "locref_stdev: 7.2801\n",
    "lr_init: 0.0005\n",
    "max_input_size: 1500\n",
    "max_shift: 0.4\n",
    "metadataset: training-datasets/iteration-0/UnaugmentedDataSet_dev-maJun14/Documentation_data-dev-ma_80shuffle1.pickle\n",
    "min_input_size: 64\n",
    "mirror: false\n",
    "multi_stage: false\n",
    "multi_step:\n",
    "- - 0.0001\n",
    "  - 7500\n",
    "- - 5.0e-05\n",
    "  - 12000\n",
    "- - 1.0e-05\n",
    "  - 200000\n",
    "net_type: dekr_w18\n",
    "num_idchannel: 0\n",
    "num_joints: 2\n",
    "num_limbs: 1\n",
    "optimizer: adam\n",
    "pafwidth: 20\n",
    "pairwise_huber_loss: false\n",
    "pairwise_loss_weight: 0.1\n",
    "pairwise_predict: false\n",
    "partaffinityfield_graph:\n",
    "- - 0\n",
    "  - 1\n",
    "partaffinityfield_predict: true\n",
    "pos_dist_thresh: 17\n",
    "pre_resize: []\n",
    "project_path: .../datasets/dev-pytorch-ma-pen-2023-06-14\n",
    "rotation: 25\n",
    "rotratio: 0.4\n",
    "save_iters: 10000\n",
    "scale_jitter_lo: 0.5\n",
    "scale_jitter_up: 1.25\n",
    "weigh_only_present_joints: false\n",
    "```\n",
    "\n",
    "### `test/inference_cfg.yaml`\n",
    "\n",
    "```yaml\n",
    "boundingboxslack: 0\n",
    "iou_threshold: 0.6\n",
    "max_age: 1\n",
    "method: m1\n",
    "min_hits: 1\n",
    "minimalnumberofconnections: 1\n",
    "pafthreshold: 0.1\n",
    "pcutoff: 0.1\n",
    "topktoretain: 2\n",
    "variant: 0\n",
    "withid: false\n",
    "```\n",
    "\n",
    "### `test/pose_cfg.yaml`\n",
    "\n",
    "```yaml\n",
    "all_joints:\n",
    "- - 0\n",
    "- - 1\n",
    "all_joints_names:\n",
    "- capTip\n",
    "- bottom\n",
    "dataset: training-datasets/iteration-0/UnaugmentedDataSet_dev-maJun14/dev-ma_pen80shuffle1.pickle\n",
    "dataset_type: multi-animal-imgaug\n",
    "global_scale: 0.8\n",
    "init_weights: .../DLCdev/deeplabcut\n",
    "location_refinement: true\n",
    "locref_smooth: false\n",
    "locref_stdev: 7.2801\n",
    "minconfidence: 0.01\n",
    "multi_stage: false\n",
    "net_type: dekr_w18\n",
    "nmsradius: 5.0\n",
    "num_idchannel: 0\n",
    "num_joints: 2\n",
    "num_limbs: 1\n",
    "pairwise_predict: false\n",
    "partaffinityfield_graph:\n",
    "- - 0\n",
    "  - 1\n",
    "partaffinityfield_predict: true\n",
    "scoremap_dir: test\n",
    "sigma: 1\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc-benchmark",
   "language": "python",
   "name": "dlc-benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
